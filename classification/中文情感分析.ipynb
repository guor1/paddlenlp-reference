{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48721ef2-4d59-4afe-93ba-2cbfc2267475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import paddle\n",
    "import pandas as pd\n",
    "from paddle.utils import run_check\n",
    "from paddle import nn\n",
    "import paddlenlp\n",
    "import paddle.nn.functional as F\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp import datasets, transformers\n",
    "from visualdl import LogWriter\n",
    "\n",
    "run_check()\n",
    "print('自然语言相关数据集：', paddle.text.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197408f-b08f-469b-9ff0-37afbd8d1206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据集\n",
    "train_ds, dev_ds, test_ds = paddlenlp.datasets.load_dataset('chnsenticorp', splits=['train', 'dev', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f6263-aea2-419f-8a70-367820e86cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ernie-3.0-medium-zh\"\n",
    "#ernie_model = paddlenlp.transformers.ErnieModel.from_pretrained(MODEL_NAME)\n",
    "model = paddlenlp.transformers.AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=len(train_ds.label_list))\n",
    "tokenizer = paddlenlp.transformers.AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7455f1-f10b-459c-bae4-ee18d2363e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理，从文本到处理好的数据，input_ids，token_type_ids\n",
    "def convert_example(example, tokenizer):\n",
    "    encoded_inputs = tokenizer(text=example[\"text\"])\n",
    "    return encoded_inputs['input_ids'], example['label']\n",
    "\n",
    "def create_train_dataloader(dataset, tokenizer, batch_size):\n",
    "    batchify_fn = lambda samples, fn=Tuple([\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "        Stack(dtype=\"int64\")\n",
    "    ]): fn(samples)\n",
    "    batch_sampler = paddle.io.DistributedBatchSampler(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return paddle.io.DataLoader(dataset=dataset, batch_sampler=batch_sampler, collate_fn=batchify_fn, return_list=True)\n",
    "    \n",
    "\n",
    "trans_func = partial(convert_example, tokenizer=tokenizer)\n",
    "train_ds.map(trans_func)\n",
    "train_data_loader = create_train_dataloader(dataset=train_ds, tokenizer=tokenizer, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0369eaa-cc79-42bb-a47e-8f652fbcada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 optimizer 优化器\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=5e-5, parameters=model.parameters())\n",
    "# 定义 loss\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "metric = paddle.metric.Accuracy()\n",
    "# 训练\n",
    "epochs = 3\n",
    "global_step = 0\n",
    "with LogWriter(logdir=\"./logs\") as writer:\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_data_loader, start=1):\n",
    "            input_ids, labels = batch\n",
    "            logits = model(input_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            probs = F.softmax(logits, axis=1)\n",
    "            # 预测分类概率\n",
    "            correct = metric.compute(logits, labels)\n",
    "            metric.update(correct)\n",
    "            acc = metric.accumulate()\n",
    "\n",
    "            writer.add_scalar(tag=\"acc\", step=global_step, value=acc)\n",
    "            # 向记录器添加一个tag为`loss`的数据\n",
    "            writer.add_scalar(tag=\"loss\", step=global_step, value=loss)\n",
    "            global_step += 1\n",
    "            if global_step % 10 == 0:\n",
    "                print(\"epoch %d, step %d: loss:%.5f, acc:%.5f\" % (epoch, step, loss, acc))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b390e84-674c-416d-8880-30c1cc935d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./trained_model/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
